<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Technical Appendix: Python vs Go RabbitMQ Performance</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f9f9f9;
        }
        
        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
        }
        
        article {
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        h1 {
            font-size: 2.2rem;
            margin-bottom: 1rem;
            color: #2c3e50;
        }
        
        h2 {
            font-size: 1.6rem;
            margin: 2rem 0 1rem 0;
            color: #34495e;
            border-bottom: 2px solid #eee;
            padding-bottom: 0.5rem;
        }
        
        h3 {
            font-size: 1.2rem;
            margin: 1.5rem 0 0.5rem 0;
            color: #495057;
        }
        
        p {
            margin-bottom: 1rem;
        }
        
        .code-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin: 2rem 0;
        }
        
        .code-section {
            border: 1px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
        }
        
        .code-header {
            background: #f4f4f4;
            padding: 10px 15px;
            font-weight: bold;
            border-bottom: 1px solid #ddd;
        }
        
        .python-header {
            background: #3776ab;
            color: white;
        }
        
        .go-header {
            background: #00add8;
            color: white;
        }
        
        pre {
            margin: 0;
            font-size: 0.9rem;
        }
        
        code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
        }
        
        .optimization-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }
        
        .optimization-card {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        
        .optimization-card h4 {
            color: #2c3e50;
            margin-bottom: 0.5rem;
        }
        
        .performance-impact {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.8rem;
            font-weight: bold;
            margin-top: 0.5rem;
        }
        
        .high-impact {
            background: #d4edda;
            color: #155724;
        }
        
        .medium-impact {
            background: #fff3cd;
            color: #856404;
        }
        
        .low-impact {
            background: #cce5ff;
            color: #004085;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border: 1px solid #ddd;
        }
        
        th {
            background: #f8f9fa;
            font-weight: bold;
        }
        
        .benchmark-chart {
            margin: 2rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 8px;
        }
        
        @media (max-width: 768px) {
            .code-comparison {
                grid-template-columns: 1fr;
            }
            
            article {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <article>
            <h1>Technical Appendix: Python vs Go RabbitMQ Performance</h1>
            
            <h2>Code Comparison: The Critical Differences</h2>
            
            <h3>The GIL Problem Illustrated</h3>
            <div class="code-comparison">
                <div class="code-section">
                    <div class="code-header python-header">Python Threading (Poor Performance)</div>
                    <pre><code class="language-python"># Python multi-threading - WORSE performance
def worker(worker_id):
    connection = pika.BlockingConnection(...)
    channel = connection.channel()
    
    for msg in messages:
        # Only one thread can execute Python 
        # bytecode at a time
        channel.basic_publish(...)  # GIL acquired/released
        
# Result: 8 threads = 5,959 msgs/sec 
# (slower than 1 thread!)</code></pre>
                </div>
                
                <div class="code-section">
                    <div class="code-header go-header">Go Goroutines (Excellent Performance)</div>
                    <pre><code class="language-go">// Go goroutines - TRUE concurrency
func worker(workerID int) {
    producer, _ := NewProducer(...)
    defer producer.Close()
    
    for msgID := range messagesCh {
        // Multiple goroutines execute 
        // simultaneously
        producer.channel.Publish(...)
    }
}
// Result: Peak 1,082,014 msgs/sec</code></pre>
                </div>
            </div>
            
            <h3>The Multiprocessing Solution</h3>
            <div class="code-comparison">
                <div class="code-section">
                    <div class="code-header python-header">Python Multiprocessing (Good Performance)</div>
                    <pre><code class="language-python"># Python multiprocessing - TRUE parallelism
def process_worker(worker_id, start_id, count):
    # Each process has its own GIL
    connection = pika.BlockingConnection(...)
    channel = connection.channel()
    
    for i in range(start_id, start_id + count):
        channel.basic_publish(...)
        
# Result: 4 processes = 72,204 msgs/sec</code></pre>
                </div>
                
                <div class="code-section">
                    <div class="code-header go-header">Go Connection Pooling</div>
                    <pre><code class="language-go">// Go with connection pool
producers := make([]*Producer, numWorkers)
for i := 0; i < numWorkers; i++ {
    producer, _ := NewProducer(...)
    producers[i] = producer
}

// Each worker uses its own connection
// No contention = maximum performance</code></pre>
                </div>
            </div>
            
            <h2>Optimization Techniques</h2>
            
            <div class="optimization-grid">
                <div class="optimization-card">
                    <h4>Remove Console Output</h4>
                    <p>Eliminated print statements in hot paths</p>
                    <pre><code class="language-python"># Before: print(f'Sent: {message}')
# After: Print only every 1000 messages</code></pre>
                    <span class="performance-impact high-impact">20x improvement</span>
                </div>
                
                <div class="optimization-card">
                    <h4>Pre-allocation</h4>
                    <p>Reuse objects instead of creating new ones</p>
                    <pre><code class="language-go">// Pre-allocate message
message := FastMessage{ID: 0, Content: ""}
// Reuse in loop
message.ID = i</code></pre>
                    <span class="performance-impact medium-impact">Reduced GC pressure</span>
                </div>
                
                <div class="optimization-card">
                    <h4>Non-persistent Messages</h4>
                    <p>Trade durability for speed</p>
                    <pre><code class="language-python"># DeliveryMode: 1 (transient)
# Instead of: 2 (persistent)</code></pre>
                    <span class="performance-impact high-impact">10x improvement</span>
                </div>
                
                <div class="optimization-card">
                    <h4>Simplified Serialization</h4>
                    <p>Minimal message structure</p>
                    <pre><code class="language-go">type FastMessage struct {
    ID      int    `json:"id"`
    Content string `json:"content"`
    // Removed timestamp
}</code></pre>
                    <span class="performance-impact medium-impact">Faster JSON encoding</span>
                </div>
            </div>
            
            <h2>Performance Bottlenecks Discovered</h2>
            
            <table>
                <tr>
                    <th>Bottleneck</th>
                    <th>Language</th>
                    <th>Impact</th>
                    <th>Solution</th>
                </tr>
                <tr>
                    <td>GIL Contention</td>
                    <td>Python</td>
                    <td>-73% with 8 threads</td>
                    <td>Use multiprocessing</td>
                </tr>
                <tr>
                    <td>Connection Sharing</td>
                    <td>Both</td>
                    <td>-63% throughput</td>
                    <td>One connection per worker</td>
                </tr>
                <tr>
                    <td>Message Persistence</td>
                    <td>Both</td>
                    <td>-95% throughput</td>
                    <td>Use transient messages</td>
                </tr>
                <tr>
                    <td>Console I/O</td>
                    <td>Both</td>
                    <td>-95% throughput</td>
                    <td>Batch logging</td>
                </tr>
                <tr>
                    <td>Timestamp Formatting</td>
                    <td>Go</td>
                    <td>Race condition</td>
                    <td>Remove or pre-initialize</td>
                </tr>
            </table>
            
            <h2>Memory and Resource Usage</h2>
            
            <div class="code-comparison">
                <div class="code-section">
                    <div class="code-header python-header">Python Memory Pattern</div>
                    <pre><code class="language-python"># Python creates new objects frequently
for i in range(message_count):
    message = {  # New dict each iteration
        'id': i,
        'content': f'Hello World #{i}',
        'timestamp': datetime.now().isoformat()
    }
    # Garbage collector runs periodically</code></pre>
                </div>
                
                <div class="code-section">
                    <div class="code-header go-header">Go Memory Pattern</div>
                    <pre><code class="language-go">// Go reuses allocated memory
message := FastMessage{}  // Allocated once
for i := 0; i < messageCount; i++ {
    message.ID = i  // Reuse same struct
    message.Content = fmt.Sprintf(...)
    // Less GC pressure
}</code></pre>
                </div>
            </div>
            
            <h2>Concurrency Models Compared</h2>
            
            <h3>Python's GIL vs Go's Goroutines</h3>
            <div class="benchmark-chart">
                <h4>Thread Scaling Performance</h4>
                <table>
                    <tr>
                        <th>Threads/Goroutines</th>
                        <th>Python (msgs/sec)</th>
                        <th>Go (msgs/sec)</th>
                        <th>Ratio</th>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>22,000</td>
                        <td>220,773</td>
                        <td>10x</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>14,749</td>
                        <td>~400,000</td>
                        <td>27x</td>
                    </tr>
                    <tr>
                        <td>8</td>
                        <td>5,959</td>
                        <td>~800,000</td>
                        <td>134x</td>
                    </tr>
                    <tr>
                        <td>20</td>
                        <td>N/A</td>
                        <td>1,082,014</td>
                        <td>∞</td>
                    </tr>
                </table>
            </div>
            
            <h2>Final Optimization: The Ultra-Fast Go Version</h2>
            
            <pre><code class="language-go">// Key optimizations that achieved 1M+ msgs/sec
func runUltraFast(messageCount int) {
    // 1. Oversubscribe CPU cores
    numWorkers := runtime.NumCPU() * 2
    
    // 2. Connection pool - no sharing
    producers := make([]*UltraFastProducer, numWorkers)
    
    // 3. Pre-allocate everything
    message := FastMessage{}
    publishing := amqp.Publishing{
        ContentType:  "application/json",
        DeliveryMode: amqp.Transient,
    }
    
    // 4. Minimal message structure
    // 5. Batch counting for progress
    // 6. Optimized channel settings
    ch.Qos(1000, 0, false)
}</code></pre>
            
            <h2>Lessons for High-Performance Messaging</h2>
            
            <ol>
                <li><strong>Understand your runtime</strong>: Python's GIL requires different strategies than Go's goroutines</li>
                <li><strong>Minimize allocations</strong>: Reuse objects and buffers where possible</li>
                <li><strong>Avoid shared state</strong>: Give each worker its own resources</li>
                <li><strong>Profile before optimizing</strong>: Our biggest gains came from unexpected places</li>
                <li><strong>Question assumptions</strong>: More threads didn't mean better performance</li>
            </ol>
            
            <div style="margin-top: 3rem; padding: 1.5rem; background: #f1f8ff; border-radius: 8px;">
                <h3>Want to reproduce these results?</h3>
                <p>All source code, Docker configurations, and detailed benchmarking scripts are available in our GitHub repository. Feel free to run the tests on your own hardware and share your results!</p>
                <p><a href="https://github.com/your-repo/rabbitmq-performance" style="color: #0366d6; text-decoration: none;">View on GitHub →</a></p>
            </div>
        </article>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>